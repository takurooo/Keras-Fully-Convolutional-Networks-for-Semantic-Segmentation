{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FCN_Keras.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"1NEVMBqa1KQY","colab_type":"text"},"cell_type":"markdown","source":["# Google Driveをマウント"]},{"metadata":{"id":"WMM_lhgWgEJD","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","!ls drive/My\\ Drive"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EQhuuezehyWr","colab_type":"text"},"cell_type":"markdown","source":["# 作業ディレクトリに移動"]},{"metadata":{"id":"EKXdQEUvxkMJ","colab_type":"code","colab":{}},"cell_type":"code","source":["import os\n","!ls drive\n","print(os.getcwd())\n","os.chdir(\"drive/My Drive/data/fcn_keras\")\n","print(os.getcwd())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B4tgmQx_h30f","colab_type":"text"},"cell_type":"markdown","source":["# SetUp"]},{"metadata":{"id":"xZNlQe-qgLPq","colab_type":"code","colab":{}},"cell_type":"code","source":["% matplotlib inline\n","import os, re, imghdr\n","import keras\n","from keras import models\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Activation, Dense, Dropout, BatchNormalization\n","from keras import optimizers\n","from keras.callbacks import TensorBoard, ModelCheckpoint\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import tensorflow as tf\n","from keras import backend as K"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AF7Yw89k1RfX","colab_type":"code","colab":{}},"cell_type":"code","source":["!ls\n","!ls models"],"execution_count":0,"outputs":[]},{"metadata":{"id":"RAyEtRVixsF5","colab_type":"code","colab":{}},"cell_type":"code","source":["from dataloader import DataLoader, Dataset\n","from models import *\n","from list_util import list_from_dir\n","from color import make_cmap\n","from transforms import label_to_img\n","\n","N_CLASS = 21\n","INPUT_SIZE = (224,224)\n","VOC_CLASSES = [\n","    \"background\",\n","    \"aeroplane\",\n","    \"bicycle\",\n","    \"bird\",\n","    \"boad\",\n","    \"bottle\",\n","    \"bus\",\n","    \"car\",\n","    \"cat\",\n","    \"chair\",\n","    \"cow\",\n","    \"dining table\",\n","    \"dog\",\n","    \"horse\",\n","    \"motor_bike\",\n","    \"person\",\n","    \"potted_plant\",\n","    \"sheep\",\n","    \"sofa\",\n","    \"train\",\n","    \"tv\"]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NWZmMuGnCA-z","colab_type":"text"},"cell_type":"markdown","source":["### ディレクトリ設定"]},{"metadata":{"id":"m1UDNJ7dj22Q","colab_type":"code","colab":{}},"cell_type":"code","source":["log_dir = \"log\"\n","os.makedirs(log_dir, exist_ok=True)\n","\n","train_data_dir = \"../datasets/voc_semseg/train\"\n","val_data_dir = \"../datasets/voc_semseg//val\"\n","\n","train_img_dir = os.path.join(train_data_dir, 'img')\n","train_gt_dir = os.path.join(train_data_dir, 'gt')\n","val_img_dir = os.path.join(val_data_dir, 'img')\n","val_gt_dir = os.path.join(val_data_dir, 'gt')\n","\n","#--------------------------------------\n","# DataLoader\n","#--------------------------------------\n","trn_dataset = Dataset(classes=N_CLASS, input_size=INPUT_SIZE,\n","                                        img_dir=train_img_dir, label_dir=train_gt_dir,\n","                                        trans=True)\n","val_dataset = Dataset(classes=N_CLASS, input_size=INPUT_SIZE,\n","                                        img_dir=val_img_dir, label_dir=val_gt_dir,\n","                                        trans=False)\n","\n","\n","\n","train_loader = DataLoader(trn_dataset, batch_size=24, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=24, shuffle=False)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sv18sC4dCEIl","colab_type":"text"},"cell_type":"markdown","source":["### データパス取得"]},{"metadata":{"id":"-kC-9Wg_g5wJ","colab_type":"code","colab":{}},"cell_type":"code","source":["train_data_paths = list_from_dir(train_img_dir, ('.jpg', '.png'))\n","train_gt_paths = list_from_dir(train_gt_dir, ('.jpg', '.png'))\n","val_data_paths = list_from_dir(val_img_dir, ('.jpg', '.png'))\n","val_gt_paths = list_from_dir(val_gt_dir, ('.jpg', '.png'))\n","\n","print(len(train_data_paths))\n","print(len(train_gt_paths))\n","print(len(val_data_paths))\n","print(len(val_gt_paths))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"p8u45FScCIDm","colab_type":"text"},"cell_type":"markdown","source":["# 学習"]},{"metadata":{"id":"VjxZ3lHbuRmd","colab_type":"text"},"cell_type":"markdown","source":["### Select model"]},{"metadata":{"id":"MIHNvxVzdXEA","colab_type":"code","colab":{}},"cell_type":"code","source":["# model = models.vgg_fcn8s.build(bilinear=True, drop_rate=0.5, weight_decay=0.00005)\n","model = models.vgg_fcn8s.build(bilinear=True, drop_rate=0, weight_decay=0)\n","# model = models.vgg_fcn32s.build(bilinear=True, drop_rate=0.5, weight_decay=0.00005)\n","# model = models.vgg_fcn32s.build(bilinear=True, drop_rate=0, weight_decay=0)\n","#  model = models.vgg_fcn16s.build(bilinear=True, drop_rate=0, weight_decay=0)\n","# model = models.vgg_fcn16s_ex.build(bilinear=True, drop_rate=0, weight_decay=0)\n","# model = models.vgg_fcn8s_ex.build(bilinear=True, drop_rate=0, weight_decay=0)\n","model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"FlKBaVLCuPlJ","colab_type":"text"},"cell_type":"markdown","source":["### Compile"]},{"metadata":{"id":"q-7w4FrRRff7","colab_type":"code","colab":{}},"cell_type":"code","source":["w = os.path.join(log_dir,\"fcn16s_bi_trans_classweight_weights-24-0.08-0.77-0.58-0.68-.hdf5\")\n","model.load_weights(w, by_name=True)\n","\n","# model = keras.models.load_model(os.path.join(log_dir, \"fcn8.hdf5\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JxBdVYETTFUO","colab_type":"code","colab":{}},"cell_type":"code","source":["class_weight = [\n","    1.,\n","    51.,\n","    151.,\n","    43.,\n","    64.,\n","    83.,\n","    23.,\n","    31.,\n","    15.,\n","    47.,\n","    51.,\n","    47.,\n","    25.,\n","    47.,\n","    36.,\n","    10.,\n","    86.,\n","    49.,\n","    46.,\n","    27.,\n","    51.\n","]\n","\n","class_weight = np.ones((N_CLASS)) * class_weight\n","class_weight /= class_weight.sum()\n","\n","print(class_weight)\n","\n","class_weight_map = class_weight"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n4-7V6pxgvhJ","colab_type":"code","colab":{}},"cell_type":"code","source":["def weighted_pixelwise_crossentropy(n_class, class_weights):\n","\n","    def loss_func(y_true, y_pred):\n","        _, h, w, _ = K.int_shape(y_pred)\n","        class_weights_tensor = tf.convert_to_tensor(class_weights, dtype=tf.float32)\n","        \n","        flat_y_true  = tf.reshape(y_true, [-1, n_class])\n","        flat_y_pred = tf.reshape(y_pred, [-1, n_class])  \n","        \n","        \n","        epsilon =K.epsilon()\n","        flat_y_pred = tf.clip_by_value(flat_y_pred, epsilon, 1.)\n","        \n","        x_entorpy = tf.multiply(flat_y_true, tf.log(flat_y_pred))        \n","        weighted_x_entropy = tf.multiply(x_entorpy, class_weights_tensor)    \n","        weighted_x_entropy_mean = - tf.reduce_sum(weighted_x_entropy) / (h*w)\n","\n","        return weighted_x_entropy_mean\n","\n","    return loss_func"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vwYNOdFDuC1E","colab_type":"code","colab":{}},"cell_type":"code","source":["#--------------------------------------\n","# Optimzier\n","#--------------------------------------\n","optimizer = optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n","#optimizer = optimizers.Adam()\n","\n","\n","#--------------------------------------\n","# Compile\n","#--------------------------------------\n","# model.compile(loss=\"categorical_crossentropy\",\n","#                             optimizer=optimizer,\n","#                             metrics=[\"accuracy\"])\n","model.compile(loss=weighted_pixelwise_crossentropy(N_CLASS, class_weight_map),\n","                            optimizer=optimizer,\n","                            metrics=[\"accuracy\"])\n","\n","#--------------------------------------\n","# Callback\n","#--------------------------------------\n","ckpt_name = 'weights-{epoch:02d}-{loss:.2f}-{acc:.2f}-{val_loss:.2f}-{val_acc:.2f}-.hdf5'\n","cbs = [\n","    ModelCheckpoint(os.path.join(log_dir, ckpt_name),\n","                    monitor='val_acc', verbose=0,\n","                    save_best_only=True,\n","                    save_weights_only=True,\n","                    mode='auto', period=1)\n","]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Zf5QlkzAuLMP","colab_type":"text"},"cell_type":"markdown","source":["### Training"]},{"metadata":{"id":"CZ02UOZksKGh","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 24\n","EPOCHS =10\n","\n","steps_per_epoch =  np.ceil(len(trn_dataset) / BATCH_SIZE)\n","validation_steps =  np.ceil(len(val_dataset) / BATCH_SIZE)\n","\n","print(\"epochs : \", EPOCHS)\n","print(\"batch_size : \", BATCH_SIZE)\n","print(\"steps_per_epoch : \", steps_per_epoch)\n","print(\"validation_steps : \", validation_steps)\n","\n","history = model.fit_generator(\n","    train_loader.flow(),\n","    steps_per_epoch=steps_per_epoch,\n","    epochs=EPOCHS,\n","    validation_data=val_loader.flow(),\n","    validation_steps=validation_steps,\n","    callbacks=cbs,\n","    verbose=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Tk7Gh2N-sTT3","colab_type":"text"},"cell_type":"markdown","source":["### Save weights"]},{"metadata":{"id":"a9vFVBPWZgTJ","colab_type":"code","colab":{}},"cell_type":"code","source":["weight_path = os.path.join(log_dir, \"fcn8_ex.hdf5\")\n","print(weight_path)\n","model.save(weight_path)\n","!ls log"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JoIfyXb6iGiQ","colab_type":"code","colab":{}},"cell_type":"code","source":["weight_path = os.path.join(log_dir, \"fcn8_weights.hdf5\")\n","print(weight_path)\n","model.save_weights(weight_path)\n","!ls log"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tz22PUMcsWfD","colab_type":"text"},"cell_type":"markdown","source":["### Training accuracy"]},{"metadata":{"id":"eEdnlYzu0Qu4","colab_type":"code","colab":{}},"cell_type":"code","source":["new_history=history\n","\n","new_acc = new_history.history['acc']\n","new_val_acc = new_history.history['val_acc']\n","acc.extend(new_acc)\n","val_acc.extend(new_val_acc)\n","\n","new_loss = new_history.history['loss']\n","new_val_loss = new_history.history['val_loss']\n","loss.extend(new_loss)\n","val_loss.extend(new_val_loss)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zLcyo4mYmAg6","colab_type":"code","colab":{}},"cell_type":"code","source":["# acc = history.history['acc']\n","# val_acc = history.history['val_acc']\n","\n","\n","epochs = range(1, len(acc)+1)\n","\n","plt.plot(epochs, acc, 'b', label='train accuracy')\n","plt.plot(epochs, val_acc, 'r', label='val accuracy')\n","plt.xticks(np.arange(0,  len(acc)+1, step=10))\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"q2cx-RtCsYwV","colab_type":"text"},"cell_type":"markdown","source":["### Training loss"]},{"metadata":{"id":"5GrXLNXhmu8m","colab_type":"code","colab":{}},"cell_type":"code","source":["# loss = history.history['loss']\n","# val_loss = history.history['val_loss']\n","\n","\n","epochs = range(1, len(acc)+1)\n","\n","plt.plot(epochs, loss, 'b', label='train loss')\n","plt.plot(epochs, val_loss, 'r', label='val loss')\n","plt.xticks(np.arange(0,  len(acc)+1, step=10))\n","\n","plt.legend()\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gIfRpkAoyOI3","colab_type":"text"},"cell_type":"markdown","source":["# 予測"]},{"metadata":{"id":"YT6M0sGqhb1p","colab_type":"code","outputId":"f2948648-9ad0-475a-ef26-52bc4a08809d","executionInfo":{"status":"ok","timestamp":1549806385597,"user_tz":-540,"elapsed":2270,"user":{"displayName":"中嶋拓郎","photoUrl":"","userId":"11259832953657969381"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"cell_type":"code","source":["model = models.vgg_fcn16s.build(bilinear=True, drop_rate=0, weight_decay=0)\n","weight_path = os.path.join(log_dir, \"fcn16s_bi_trans_weights-04-0.26-0.92-0.83-0.78-.hdf5\")\n","print('load weight : ', weight_path)\n","model.load_weights(weight_path, by_name=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/root/.keras/models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","load weight :  log/fcn16s_bi_trans_weights-04-0.26-0.92-0.83-0.78-.hdf5\n"],"name":"stdout"}]},{"metadata":{"id":"JvyUhdPWk7PW","colab_type":"text"},"cell_type":"markdown","source":["# eval"]},{"metadata":{"id":"PvM3Cvtpr-6r","colab_type":"text"},"cell_type":"markdown","source":["### Load weights"]},{"metadata":{"id":"S-js0FAzjuSs","colab_type":"code","colab":{}},"cell_type":"code","source":["model = models.vgg_fcn32s.build(bilinear=True, drop_rate=0, weight_decay=0)\n","\n","# w = os.path.join(log_dir,\"fcn32s_bi_trans_weights-10-0.24-0.91-0.65-0.80-.hdf5\")\n","w = os.path.join(log_dir,\"fcn32s_bi_trans_class_weights-09-0.32-0.89-0.65-0.79-.hdf5\")\n","\n","model.load_weights(w, by_name=True)\n","\n","optimizer = optimizers.SGD(lr=0.00001, momentum=0.9, nesterov=True)\n","model.compile(loss=\"categorical_crossentropy\",\n","                            optimizer=optimizer,\n","                            metrics=[\"accuracy\"])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"unnx_HhRsBcE","colab_type":"text"},"cell_type":"markdown","source":["### Prediction"]},{"metadata":{"id":"gfn04uGB1hSh","colab_type":"code","colab":{}},"cell_type":"code","source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","import numpy as np"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rbIa1dAAg9NL","colab_type":"code","colab":{}},"cell_type":"code","source":["img_idx = 2\n","\n","#---------------------------\n","# Load test image\n","#---------------------------\n","# test_dataset = Dataset(classes=N_CLASS, input_size=INPUT_SIZE,\n","#                                         img_dir=val_img_dir,\n","#                                         label_dir=val_gt_dir,\n","#                                         trans=False)\n","test_dataset = Dataset(classes=N_CLASS, input_size=INPUT_SIZE,\n","                                        img_dir=train_img_dir,\n","                                        label_dir=train_gt_dir,\n","                                        trans=False)\n","input_img, gt_img = test_dataset[img_idx]\n","\n","#---------------------------\n","# Output prediction\n","#---------------------------\n","import time\n","start_time = time.time()\n","pred = model.predict(input_img)\n","end_time = time.time()\n","print(\"{} msec\".format((end_time-start_time) * 1000))\n","\n","loss, acc = model.evaluate(input_img, gt_img)\n","print(\"acc  : {}\".format(acc*100))\n","print(\"loss : {}\".format(loss*100))\n","\n","print(pred.shape)\n","\n","\n","#---------------------------\n","# Show original image\n","#---------------------------\n","# im = Image.open(input_img_path)\n","# im = np.asarray(im)\n","# plt.imshow(im)\n","# plt.show()\n","\n","#---------------------------\n","# Input img\n","#---------------------------\n","input_img_ = (input_img[0] + 1) * 127.5\n","input_img_ = np.uint8(input_img_)\n","\n","#---------------------------\n","# GT img\n","#---------------------------\n","gt_img_ = label_to_img(gt_img[0])\n","\n","#---------------------------\n","# Prediction img\n","#---------------------------\n","predicted_img = label_to_img(pred[0])\n","\n","#---------------------------\n","# Show imgs\n","#---------------------------\n","plt.figure(figsize=(15,15))\n","img_list = [input_img_, gt_img_, predicted_img]\n","titel_list = [\"input img\", \"gt img\", \"predicted img\"]\n","plot_num = 1\n","for title, img in zip(titel_list, img_list):\n","    plt.subplot(1,3, plot_num)\n","    plt.title(title)\n","    plt.axis(\"off\")\n","    plt.imshow(img)\n","    plot_num += 1\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"PG5jjcu55f1p","colab_type":"text"},"cell_type":"markdown","source":["### クラスごとのaccを調査"]},{"metadata":{"id":"-_0za8ottabt","colab_type":"code","colab":{}},"cell_type":"code","source":["def acc_per_class(pred, gt):\n","    # pred.shape is (HxWxC) and pred_idx.shape is (HxW)\n","    pred_idx = np.argmax(pred, axis=2)\n","\n","    pred_maps = np.zeros(pred.shape)\n","    pred_h, pred_w, pred_ch = pred.shape\n","\n","    for row in range(pred_h):\n","        for col in range(pred_w):\n","            idx = pred_idx[row, col]\n","            pred_maps[row, col, idx] = 1\n","\n","    ans = pred_maps * gt\n","\n","    for class_idx in range(pred_ch):\n","        gt_sum = gt[:,:,class_idx].sum()\n","        ans_sum = ans[:,:,class_idx].sum()\n","\n","        if gt_sum != 0:\n","            acc = ans_sum / gt_sum * 100\n","        else:\n","            acc = 0\n","        print(\"class : {:02d}  gt_pixel : {}  ans_pixel : {}  acc : {}\".format(class_idx, gt_sum, ans_sum, acc))\n","        \n","        \n","acc_per_class(pred[0], gt_img[0])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0ODPy4rNF3vy","colab_type":"text"},"cell_type":"markdown","source":["### クラスごとのピクセル数を調査"]},{"metadata":{"id":"n98oaqQqqVzU","colab_type":"code","colab":{}},"cell_type":"code","source":["from PIL import Image\n","\n","\n","dataset = trn_dataset\n","\n","input_img, gt_img = dataset[6]\n","\n","print(\"---------------------------\")\n","print(\"class pixel cnt\")\n","for i, class_name in enumerate(VOC_CLASSES):\n","    class_cnt = np.count_nonzero(gt_img[0, :, :, i] == 1)\n","    print(\"{:02d} {} {}\".format(i, class_name.ljust(15), class_cnt))\n","print(\"---------------------------\")\n","    \n","plt.figure(figsize=(10,10))\n","plt.imshow(label_to_img(gt_img[0]))\n","plt.axis(\"off\")\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5F3JEcdK5Jtm","colab_type":"text"},"cell_type":"markdown","source":["### データセット内の各クラスのピクセル数をカウント"]},{"metadata":{"id":"P2VmLD4iwfCi","colab_type":"code","colab":{}},"cell_type":"code","source":["def voc_count_class(dataset, n_class):\n","    voc_counter = np.zeros(n_class)\n","    for _, gt_img in dataset:\n","        for i in range(n_class):\n","            cnt = np.count_nonzero(gt_img[0, :, :, i] == 1)\n","            if cnt != 0:\n","                voc_counter[i] += int(cnt)\n","    return voc_counter\n","\n","# GTを224x224でクロップしたときの各クラスのピクセル数をカウント\n","voc_counter = voc_count_class(dataset, N_CLASS)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KHA1NGWXidxX","colab_type":"code","colab":{}},"cell_type":"code","source":["print(voc_counter.sum())\n","print(voc_counter.sum() / (224*224))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IlbhGqjK5V1q","colab_type":"text"},"cell_type":"markdown","source":["### classごとの比率を計算"]},{"metadata":{"id":"_PDGYSBNZMQS","colab_type":"code","colab":{}},"cell_type":"code","source":["voc_class_sum = voc_counter.sum()\n","for i, class_cnt in enumerate(voc_counter):\n","    rate = class_cnt/voc_class_sum * 100\n","    print(\"{:.2f}% \\t{:10} \\t{} \".format(rate, int(class_cnt), VOC_CLASSES[i]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8EE2xw9t5YJ0","colab_type":"text"},"cell_type":"markdown","source":["### classごとのウエイトを計算"]},{"metadata":{"id":"j4skDG6cEca3","colab_type":"code","colab":{}},"cell_type":"code","source":["# class_weightを計算\n","voc_class_max = voc_counter.max()\n","for class_name, class_cnt in zip(VOC_CLASSES, voc_counter):\n","     print(\"{:4d}    \\t{}\".format(int(voc_class_max/class_cnt), class_name))"],"execution_count":0,"outputs":[]}]}